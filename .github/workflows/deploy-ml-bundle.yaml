# This is a basic workflow to help you get started with Actions

name: deploy-ml-bundle

# Controls when the workflow will run
on:

  workflow_dispatch:
    inputs:
      project_name:
        description: ML use case name
        type: string
        required: true
      organization:
        description: GitHub organization name
        type: string
        default: "digital-power"
      model_schema:
        description: Schema where models will be stored
        type: string
        default: "meerlanden_schema"
      inference_table:
        description: Table where the inferences will be stored
        type: string
        default: "meerlanden_inference_table"
      include_feature_store:
        type: choice
        description: Whether to include Feature Store
        options:
          - "no"
          - "yes"
        default: "no"
        required: true
env:
  PYTHON_VERSION: '3.10'

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:

  create-repo:
    runs-on: ubuntu-latest
    environment: default
    steps:
      - name: Create repository
        env:
          GH_TOKEN: ${{ secrets.ADMIN_GITHUB_TOKEN }}
        run: |
          sudo apt install gh -y
          gh repo create ${{ inputs.organization }}/${{ inputs.project_name }} --public --description "ML project for ${{ inputs.project_name }} "

  initialize-repo:
    runs-on: ubuntu-latest
    environment: default
    needs: create-repo
    steps:
      - name: Setup Databricks CLI
        uses: databricks/setup-cli@main

      - name: Initialize bundle
        env:
          DATABRICKS_HOST: ${{ vars.DATABRICKS_STAGING_WORKSPACE_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          echo '{
            "input_setup_cicd_and_project": "CICD_and_Project",
            "input_project_name": "${{ inputs.project_name }}",
            "input_cloud": "${{ vars.DATABRICKS_CLOUD }}",
            "input_cicd_platform": "${{ vars.DATABRICKS_CICD_PLATFORM }}",
            "input_databricks_staging_workspace_host": "${{ vars.DATABRICKS_STAGING_WORKSPACE_HOST }}",
            "input_databricks_prod_workspace_host": "${{ vars.DATABRICKS_PROD_WORKSPACE_HOST }}",
            "input_default_branch": "main",
            "input_release_branch": "release",
            "input_read_user_group": "${{ vars.DATABRICKS_READ_USER_GROUP }}",
            "input_include_models_in_unity_catalog": "yes",
            "input_staging_catalog_name": "${{ vars.DATABRICKS_STAGING_CATALOG_NAME }}",
            "input_prod_catalog_name": "${{ vars.DATABRICKS_PROD_CATALOG_NAME }}",
            "input_test_catalog_name": "${{ vars.DATABRICKS_TEST_CATALOG_NAME }}",
            "input_schema_name": "${{ inputs.model_schema }}",
            "input_unity_catalog_read_user_group": "${{ vars.DATABRICKS_UNITY_CATALOG_READ_USER_GROUP }}",
            "input_inference_table_name": "${{ inputs.inference_table }}",
            "input_include_feature_store": "${{ inputs.include_feature_store }}",
            "input_include_mlflow_recipes": "no"
          }' > config.json
          cat config.json
          # databricks bundle init mlops-stacks --config-file config.json
          # read this https://docs.databricks.com/en/dev-tools/bundles/mlops-stacks.html
          # also check this https://github.com/databricks/mlops-stacks
          # and also this https://gist.github.com/DaniJG/b21170482545ad8c93874d164fd97a90 and this
          # https://github.com/databricks/mlops-stacks/blob/main/tests/example-project-configs/azure/azure-github.json